{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 60000\n",
      "Test set size: 10000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform (convert to tensor and normalize)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download MNIST dataset\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Print dataset size\n",
    "print(\"Training set size:\", len(train_dataset))\n",
    "print(\"Test set size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch of images shape: torch.Size([32, 1, 28, 28])\n",
      "Batch of labels shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Get one batch of data\n",
    "for images, labels in train_loader:\n",
    "    print(\"Batch of images shape:\", images.shape)  # (batch_size, 1, 28, 28)\n",
    "    print(\"Batch of labels shape:\", labels.shape)  # (batch_size,)\n",
    "    break  # Just to print one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_loader.dataset.data.numpy().reshape(-1,28*28)/255.0\n",
    "y_train = train_loader.dataset.targets.numpy()\n",
    "X_test = test_loader.dataset.data.numpy().reshape(-1,28*28)/255.0\n",
    "y_test = test_loader.dataset.targets.numpy()\n",
    "\n",
    "def one_hot_encode(y, num_classes=10):\n",
    "    return np.eye(num_classes)[y]\n",
    "\n",
    "y_train_oh = one_hot_encode(y_train)\n",
    "y_test_oh = one_hot_encode(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def relu_derivative(Z):\n",
    "    return Z > 0\n",
    "\n",
    "def softmax(Z):\n",
    "    expZ = np.exp(Z - np.max(Z,axis=1,keepdims=True))\n",
    "    return expZ/np.sum(expZ,axis=1,keepdims=True)\n",
    "\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    return -np.mean(np.sum(y_true * np.log(y_pred + 1e-9), axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(input_dim,hidden_layer,output_dim):\n",
    "    W1 = np.random.randn(input_dim,hidden_layer)*0.01\n",
    "    b1 = np.zeros((1,hidden_layer))\n",
    "    W2 = np.random.randn(hidden_layer,output_dim)*0.01\n",
    "    b2 = np.zeros((1,output_dim))\n",
    "    return W1,b1,W2,b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X,W1,b1,W2,b2):\n",
    "    Z1 = np.dot(X,W1) + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(A1,W2) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1,A1,Z2,A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, y, Z1, A1, Z2, A2, W1, W2):\n",
    "    m = X.shape[0]\n",
    "\n",
    "    # Gradients\n",
    "    dZ2 = A2 - y  # Error in output layer\n",
    "    dW2 = np.dot(A1.T, dZ2) / m\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "\n",
    "    dA1 = np.dot(dZ2, W2.T)\n",
    "    dZ1 = dA1 * relu_derivative(Z1)  # Applying ReLU derivative\n",
    "    dW1 = np.dot(X.T, dZ1) / m\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "\n",
    "    return dW1, db1, dW2, db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 1.2724\n",
      "Epoch 2/15, Loss: 0.4308\n",
      "Epoch 3/15, Loss: 0.3498\n",
      "Epoch 4/15, Loss: 0.3154\n",
      "Epoch 5/15, Loss: 0.2916\n",
      "Epoch 6/15, Loss: 0.2715\n",
      "Epoch 7/15, Loss: 0.2537\n",
      "Epoch 8/15, Loss: 0.2380\n",
      "Epoch 9/15, Loss: 0.2237\n",
      "Epoch 10/15, Loss: 0.2111\n",
      "Epoch 11/15, Loss: 0.1997\n",
      "Epoch 12/15, Loss: 0.1895\n",
      "Epoch 13/15, Loss: 0.1799\n",
      "Epoch 14/15, Loss: 0.1714\n",
      "Epoch 15/15, Loss: 0.1636\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_size = 784  # 28x28\n",
    "hidden_size = 128\n",
    "output_size = 10\n",
    "learning_rate = 0.01\n",
    "epochs = 15\n",
    "batch_size = 32\n",
    "\n",
    "# Initialize weights\n",
    "W1, b1, W2, b2 = initialize_weights(input_size, hidden_size, output_size)\n",
    "\n",
    "losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    permutation = np.random.permutation(X_train.shape[0])  # Shuffle data\n",
    "    X_train_shuffled = X_train[permutation]\n",
    "    y_train_shuffled = y_train_oh[permutation]\n",
    "\n",
    "    total_loss = 0\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        X_batch = X_train_shuffled[i:i+batch_size]\n",
    "        y_batch = y_train_shuffled[i:i+batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        Z1, A1, Z2, A2 = forward(X_batch, W1, b1, W2, b2)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = cross_entropy_loss(y_batch, A2)\n",
    "        losses.append(loss)\n",
    "        total_loss += loss\n",
    "\n",
    "        # Backpropagation\n",
    "        dW1, db1, dW2, db2 = backward_propagation(X_batch, y_batch, Z1, A1, Z2, A2, W1, W2)\n",
    "\n",
    "        # Update weights\n",
    "        W1 -= learning_rate * dW1\n",
    "        b1 -= learning_rate * db1\n",
    "        W2 -= learning_rate * dW2\n",
    "        b2 -= learning_rate * db2\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / (X_train.shape[0] / batch_size):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 95.43%\n"
     ]
    }
   ],
   "source": [
    "def predict(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward(X, W1, b1, W2, b2)\n",
    "    return np.argmax(A2, axis=1)\n",
    "\n",
    "y_pred = predict(X_test, W1, b1, W2, b2)\n",
    "accuracy = np.mean(y_pred == y_test) * 100\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X_train[1],W1,b1,W2,b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
